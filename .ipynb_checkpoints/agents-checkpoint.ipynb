{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fab69ce-98b2-4a93-8af2-3a60436ddf18",
   "metadata": {},
   "source": [
    "# Coding agents from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c6783163-6d55-49a0-aa9b-7b073039bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b8267467-be8d-4ed2-8915-e0d1f7c51895",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = load_dotenv()\n",
    "api_key: str = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4728c126-9abe-45f0-9fda-785ec0812665",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b345d741-999d-4bf0-8e06-e63a954733e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"developer\",\n",
    "        \"content\": [{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"You are a helpful assistant who answers in the style of a Southern Belle\"\n",
    "    }]},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"What's the capital of France?\"\n",
    "    }]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c5d7a702-99af-4701-90ef-9afb4ed4dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    max_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d7af0c52-5c4c-44bc-8930-7f34b5e29984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well, darling, the capital of France is none other than the charming city of Paris. It‚Äôs simply delightful, with its lovely caf√©s, stunning architecture, and that oh-so-romantic ambiance. If you ever get the chance to sip a caf√© au lait there, I highly recommend it!'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe5df5d-de54-4a35-9c6a-0f2423c561d4",
   "metadata": {},
   "source": [
    "## Agentic workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824af71e-de4c-4e62-a804-446825325ae2",
   "metadata": {},
   "source": [
    "### Prompt-Chaining: Decompose a task into sequential subtasks, where each step builds on previous results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb436403-d6c4-4a4c-aa8d-6c02047397e9",
   "metadata": {},
   "source": [
    "#### Example 1: Chain workflow for structured data extraction and formatting\n",
    "Each step progressively transforms raw text into a formatted table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7cc80523-e421-4b31-aa8d-e1e2348e95c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_processing_steps = [\n",
    "    \"\"\"Extract only the numerical values and their associated metrics from the text.\n",
    "    Format each as 'value: metric' on a new line.\n",
    "    Example format:\n",
    "    92: customer satisfaction\n",
    "    45%: revenue growth\"\"\",\n",
    "    \n",
    "    \"\"\"Convert all numerical values to percentages where possible.\n",
    "    If not a percentage or points, convert to decimal (e.g., 92 points -> 92%).\n",
    "    Keep one number per line.\n",
    "    Example format:\n",
    "    92%: customer satisfaction\n",
    "    45%: revenue growth\"\"\",\n",
    "    \n",
    "    \"\"\"Sort all lines in descending order by numerical value.\n",
    "    Keep the format 'value: metric' on each line.\n",
    "    Example:\n",
    "    92%: customer satisfaction\n",
    "    87%: employee satisfaction\"\"\",\n",
    "    \n",
    "    \"\"\"Format the sorted data as a markdown table with columns, without tags or enclosing quotes:\n",
    "    | Metric | Value |\n",
    "    |:--|--:|\n",
    "    | Customer Satisfaction | 92% |\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b8489c39-929f-4eec-be11-44b48844a139",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chainer:\n",
    "    def __init__(self, system_prompt, steps, inp, model, api_key):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.steps = steps\n",
    "        self.inp = inp\n",
    "        self.model = model\n",
    "        self.system_prompt = {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": [{\n",
    "                \"type\": \"text\",\n",
    "                \"text\": system_prompt\n",
    "            }]\n",
    "        }\n",
    "\n",
    "\n",
    "    def chain(self, verbose=False):\n",
    "        chain = [self.system_prompt]\n",
    "        current_input = self.inp\n",
    "        for ix, step in enumerate(self.steps):            \n",
    "            new_step = {\n",
    "                \"role\": \"user\",\n",
    "                \"content\":\n",
    "                [{\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\":f\"{step}\\nInput: {current_input}\\n\"\n",
    "                }]\n",
    "            }\n",
    "            chain.append(new_step)\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=chain,\n",
    "                max_completion_tokens=3000)\n",
    "            response_content = response.choices[0].message.content\n",
    "            \n",
    "            # Add the assistant's response to the chain\n",
    "            assistant_response = {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": [{\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": response_content\n",
    "                }]\n",
    "            }\n",
    "            chain.append(assistant_response)\n",
    "            if verbose:\n",
    "                print(f\"STEP: {ix}\")\n",
    "                print(response_content)\n",
    "                print(\"=\"*36)\n",
    "            current_input = response_content\n",
    "        return response_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e54d1d17-f96f-4465-b33d-57f716e92d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant specializing in marketing analysis.\"\n",
    "\n",
    "report = \"\"\"\n",
    "Q3 Performance Summary:\n",
    "Our customer satisfaction score rose to 92 points this quarter.\n",
    "Revenue grew by 45% compared to last year.\n",
    "Market share is now at 23% in our primary market.\n",
    "Customer churn decreased to 5% from 8%.\n",
    "New user acquisition cost is $43 per user.\n",
    "Product adoption rate increased to 78%.\n",
    "Employee satisfaction is at 87 points.\n",
    "Operating margin improved to 34%.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "dc55aaea-99b7-49f7-bf58-e94ac51fb548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP: 0\n",
      "92: customer satisfaction  \n",
      "45%: revenue growth  \n",
      "23%: market share  \n",
      "5%: customer churn  \n",
      "$43: new user acquisition cost  \n",
      "78%: product adoption rate  \n",
      "87: employee satisfaction  \n",
      "34%: operating margin  \n",
      "====================================\n",
      "STEP: 1\n",
      "92%: customer satisfaction  \n",
      "45%: revenue growth  \n",
      "23%: market share  \n",
      "5%: customer churn  \n",
      "$43: new user acquisition cost  \n",
      "78%: product adoption rate  \n",
      "87%: employee satisfaction  \n",
      "34%: operating margin  \n",
      "====================================\n",
      "STEP: 2\n",
      "92%: customer satisfaction  \n",
      "87%: employee satisfaction  \n",
      "78%: product adoption rate  \n",
      "45%: revenue growth  \n",
      "34%: operating margin  \n",
      "23%: market share  \n",
      "5%: customer churn  \n",
      "$43: new user acquisition cost  \n",
      "====================================\n",
      "STEP: 3\n",
      "| Metric | Value |\n",
      "|:--|--:|\n",
      "| Customer Satisfaction | 92% |\n",
      "| Employee Satisfaction | 87% |\n",
      "| Product Adoption Rate | 78% |\n",
      "| Revenue Growth | 45% |\n",
      "| Operating Margin | 34% |\n",
      "| Market Share | 23% |\n",
      "| Customer Churn | 5% |\n",
      "| New User Acquisition Cost | $43 |\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "chainer1 = Chainer(system_prompt=system_prompt, steps=data_processing_steps, inp=report, model=\"gpt-4o\", api_key=api_key)\n",
    "out = chainer1.chain(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "11ae3e92-38f3-497d-9d94-d859bc8e793b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Metric | Value |\n",
       "|:--|--:|\n",
       "| Customer Satisfaction | 92% |\n",
       "| Employee Satisfaction | 87% |\n",
       "| Product Adoption Rate | 78% |\n",
       "| Revenue Growth | 45% |\n",
       "| Operating Margin | 34% |\n",
       "| Market Share | 23% |\n",
       "| Customer Churn | 5% |\n",
       "| New User Acquisition Cost | $43 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88bec81-f1fd-4788-8ef7-2b4b99f31185",
   "metadata": {},
   "source": [
    "**Expected output**\n",
    "\n",
    "| Metric | Value |\n",
    "|:--|--:|\n",
    "| Customer Satisfaction | 92% |\n",
    "| Employee Satisfaction | 87% |\n",
    "| Product Adoption Rate | 78% |\n",
    "| Revenue Growth | 45% |\n",
    "| User Acquisition Cost | 43.00 |\n",
    "| Operating Margin | 34% |\n",
    "| Market Share | 23% |\n",
    "| Previous Customer Churn | 8% |\n",
    "| Customer Churn | 5% |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "1f4fe994-cfa4-452a-8d9d-004b9f532bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Metric | Value |\n",
      "|:--|--:|\n",
      "| Customer Satisfaction | 92% |\n",
      "| Employee Satisfaction | 87% |\n",
      "| Product Adoption Rate | 78% |\n",
      "| Revenue Growth | 45% |\n",
      "| Operating Margin | 34% |\n",
      "| Market Share | 23% |\n",
      "| Customer Churn | 5% |\n",
      "| New User Acquisition Cost | $43 |\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ff299e-6688-4f5d-82aa-06bbc3f9bc04",
   "metadata": {},
   "source": [
    "#### Example 2: Chain workflow to anonymise, translate and restyle text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d6d822b0-b2f0-481c-b525-f9d9adabb488",
   "metadata": {},
   "outputs": [],
   "source": [
    "anonymize_and_translate_steps = [\n",
    "    \"\"\"\"Perform named entity recognition NER on the text, enclosing each entity in the appropriate tag.\n",
    "    <example>\n",
    "    Before: 'Mr. Smith went to London, where he met his wife Jane Smith and his partner Leonard Farley'\n",
    "    After: 'Mr. <LASTNAME>Smith</LASTNAME> went to <CITY>London</CITY>, where he met his wife, <FIRSTNAME>Jane</FIRSTNAME><LASTNAME>Smith</LASTNAME>and his partner<FIRSTNAME>Leonard</FIRSTNAME><LASTNAME>Farley</LASTNAME>\n",
    "    </example>\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"Anonymize the text, replacing each entity marked with a tag with a pseudonym.\n",
    "    Make sure to preserve the meaning and content of sentence by replacing each entity with the same pseudonym.\n",
    "    <example>\n",
    "    Before: 'Mr. <LASTNAME>Smith</LASTNAME> went to <CITY>London</CITY>, where he met his wife, <FIRSTNAME>Jane</FIRSTNAME><LASTNAME>Smith</LASTNAME>and his partner<FIRSTNAME>Leonard</FIRSTNAME><LASTNAME>Farley</LASTNAME>,\n",
    "    After: 'Mr. Frum went to Balberry,where he met with his wife, Ellen Frum, and his partner, Algernon Leiter.\n",
    "    </example>\n",
    "    \"\"\",\n",
    "    \"\"\"Translate the anonymized text in Italian.\"\"\",\n",
    "    \"\"\"Turn the Italian into verses\"\"\",\n",
    "    \"\"\"Turn the verse into romanesco, in the style of Belli\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b1eab1-f293-4258-a007-686dc619e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "secretary_prompt = \"You are a helpful secretary who values confidentiality and is adept at translations\"\n",
    "text = \"It was a rainy day in Glasgow, when brothers Chad and John Smith embarked on their journey to Rome, where they hoped they would meet General Tso and his chicken\"\n",
    "chainer2 = Chainer(system_prompt=secretary_prompt, steps=anonymize_and_translate_steps, inp=text, model=\"gpt-4o\", api_key=api_key)\n",
    "tradit = chainer2.chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf75771-c8a4-4937-adc4-9505724b38b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tradit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd469d8-56fb-4ed5-9bb3-874090c8d1f5",
   "metadata": {},
   "source": [
    "#### Example 3: Chain workflow to create and perfect blog posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873059bf-befd-43fc-9942-bd6fb4c157e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blogger(Chainer):\n",
    "    def __init__(self, topic, target_audience, word_count, model=\"gpt-4\", api_key=None):\n",
    "        # Define the system prompt for blog post generation\n",
    "        system_prompt = \"\"\"You are a professional blog content creator who specializes in creating\n",
    "        high-quality, engaging blog posts on various topics. You follow SEO best practices\n",
    "        and create content that is both informative and engaging.\"\"\"\n",
    "        \n",
    "        # Define the steps for the blog post creation pipeline\n",
    "        steps = [\n",
    "            # Step 1: Generate an outline\n",
    "            \"\"\"Create a detailed outline for a blog post on the given topic.\n",
    "            Include a title, introduction, 4-6 main sections with subpoints, and conclusion.\n",
    "            Format the outline with clear headings and bullet points.\"\"\",\n",
    "            \n",
    "            # Step 2: Validate and refine the outline\n",
    "            \"\"\"Review the outline and ensure it meets these criteria:\n",
    "            - Covers the topic comprehensively\n",
    "            - Flows logically from point to point\n",
    "            - Addresses the needs of the target audience\n",
    "            - Includes specific, actionable information\n",
    "            If any criteria are not met, refine the outline accordingly.\"\"\",\n",
    "            \n",
    "            # Step 3: Expand the outline into a complete post\n",
    "            \"\"\"Based on the validated outline, write the complete blog post.\n",
    "            Include all of the following:\n",
    "            1. An engaging title\n",
    "            2. A hook-filled introduction\n",
    "            3. Well-developed main sections with subheadings\n",
    "            4. A strong conclusion with a call-to-action\n",
    "            5. Write in a conversational but professional tone    \n",
    "            The complete post should be approximately {word_count} words.\"\"\"\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        # Prepare input for the chaining process\n",
    "        input_data = f\"\"\"\n",
    "        Topic: {topic}\n",
    "        Target Audience: {target_audience}\n",
    "        Approximate Word Count: {word_count}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize the parent class\n",
    "        super().__init__(system_prompt, steps, input_data, model, api_key)\n",
    "    \n",
    "    def generate_blog_post(self, verbose=True):\n",
    "        \"\"\"Generate a complete blog post using the chaining process\"\"\"\n",
    "        print(f\"üöÄ Starting blog post generation process...\")\n",
    "        result = self.chain(verbose=verbose)\n",
    "        print(f\"‚úÖ Blog post generation complete!\")\n",
    "        return result\n",
    "    \n",
    "    def save_to_file(self, filename):\n",
    "        \"\"\"Save the generated blog post to a markdown file\"\"\"\n",
    "        blog_post = self.generate_blog_post(verbose=False)\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(blog_post)\n",
    "        print(f\"üìù Blog post saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a1c13-e4b6-4146-a54a-88b46e82cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "blogger = Blogger(\n",
    "    topic=\"Philosophy of Logic\",\n",
    "    target_audience=\"advanced undergraduate and graduate students in Philosophy, Computer Science and Mathematics\",\n",
    "    word_count=1400,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=api_key\n",
    ")\n",
    "post = blogger.generate_blog_post()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c0291f-c37c-4605-898c-a32f6ba3486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Markdown(post))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deb19c4-273b-4c73-95da-a5e8117afde1",
   "metadata": {},
   "source": [
    "### Routing: Dynamically selects specialized LLM paths based on input characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3746fa70-2695-44d1-9ab8-d77f30be7558",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMPrompt:\n",
    "    def __init__(self, role, prompt_type, prompt_message):\n",
    "        return {\n",
    "            \"role\": role,\n",
    "            \"content\": [{\n",
    "                \"type\": prompt_type,\n",
    "                prompt_type: prompt_message\n",
    "            }]\n",
    "        }\n",
    "            \n",
    "class LLMAgentSystemPrompt(Prompt):\n",
    "    super.__init__(self, role=\"developer\", prompt_type=\"text\")\n",
    "    def __init__(self, system_prompr\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db1551-11c0-4bff-b613-55985b6c7442",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMAgent:\n",
    "    def __init__(self, system_prompt, choices, routes, model, api_key):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.model = model\n",
    "        self.system_prompt = {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": [{\n",
    "                \"type\": \"text\",\n",
    "                \"text\": system_prompt\n",
    "            }]\n",
    "        }\n",
    "    def __init__(self, system_prompt, model, api_key):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1931557d-2b38-4391-8f57-8a5633c9aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(LLMAgent):\n",
    "    gating_prompt: str\n",
    "    choices: List(str)\n",
    "    routes: List(str)\n",
    "\n",
    "    def __init__(self, system_prompt, choices, routes, model, api_key):\n",
    "        self.system_prompt(    \n",
    "    def route\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
